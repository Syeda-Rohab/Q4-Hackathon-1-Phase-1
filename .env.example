# AI-Native Textbook Environment Variables
# Copy this file to .env and fill in your actual values
# Never commit .env to version control!

# ============================================================
# Anthropic API (Required for content generation)
# ============================================================
# Get your API key from: https://console.anthropic.com
# Free tier provides sufficient credits for 6-8 chapters
ANTHROPIC_API_KEY=sk-ant-api03-your-api-key-here

# ============================================================
# Database (Neon PostgreSQL)
# ============================================================
# Connection string format: postgresql://user:password@host:port/database
# Get from: https://neon.tech (free tier available)
DATABASE_URL=postgresql://user:password@host.neon.tech:5432/textbook_dev

# Optional: Database connection pool settings
DATABASE_POOL_MIN_SIZE=1
DATABASE_POOL_MAX_SIZE=10

# ============================================================
# Qdrant Vector Database (Optional for RAG - separate feature)
# ============================================================
# For local development, use Docker: docker run -p 6333:6333 qdrant/qdrant
# For cloud: https://cloud.qdrant.io (free tier available)
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=

# ============================================================
# Application Settings
# ============================================================
# Environment: development, staging, production
NODE_ENV=development

# Backend API settings
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000

# CORS settings (comma-separated origins)
CORS_ORIGINS=http://localhost:3000,http://localhost:8000

# ============================================================
# Content Generation Settings
# ============================================================
# Number of chapters to generate (6 for MVP, 8 for extended)
CHAPTERS_COUNT=6

# LLM model configuration
# Options: claude-3-5-sonnet-20241022, claude-3-haiku-20240307
LLM_MODEL_CHAPTERS=claude-3-5-sonnet-20241022
LLM_MODEL_ENHANCEMENTS=claude-3-haiku-20240307

# Generation parameters
MAX_RETRIES=3
RATE_LIMIT_DELAY_SECONDS=5

# ============================================================
# Logging
# ============================================================
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# ============================================================
# Deployment (Production only)
# ============================================================
# Vercel deployment (website)
# VERCEL_URL=https://your-app.vercel.app

# Railway deployment (backend)
# RAILWAY_STATIC_URL=https://your-backend.railway.app
